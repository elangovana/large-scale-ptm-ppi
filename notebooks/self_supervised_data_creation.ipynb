{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create self supervised dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sagemaker,  io\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"../chemprot_abstract_train.json\"\n",
    "test_data_file = \"../chemprot_abstract_test.json\"\n",
    "val_data_file = \"../chemprot_abstract_val.json\"\n",
    "\n",
    "\n",
    "s3_external_sources = [\"s3://aegovan-data/pubmed-json/pubmed19n0908.json\", \n",
    "                      \"s3://aegovan-data/pubmed-json/pubmed19n0907.json\",\n",
    "                      \"s3://aegovan-data/pubmed-json/pubmed19n0906.json\"\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords1 = [\"activation\", \"trigger\", \"interact\", \"inhibit\", \"regulat\", \"supress\"]\n",
    "\n",
    "keywords2 = [\"gene\", \"protein\", \"chemical\"]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def load_unique_abstract(datafile):\n",
    "    with open(datafile) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    abstracts = set()\n",
    "    results = []\n",
    "    \n",
    "    for r in data:\n",
    "        if r[\"abstract_id\"] not in abstracts:\n",
    "            abstracts.add(r[\"abstract_id\"])\n",
    "            results.append({\n",
    "                \"abstract_id\" : r[\"abstract_id\"],\n",
    "                 \"abstract\" : r[\"abstract\"]\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def self_label(df):\n",
    "   \n",
    "\n",
    "    df[\"self_label\"] = df[\"abstract\"].apply(lambda x: any([ k.lower() in x.lower() for k in keywords1]) \n",
    "                                        and sum([  k.lower() in x.lower() for k in keywords2])>=2\n",
    "                                     \n",
    "                                       )\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def randomly_substitute_keywords(x):\n",
    "    words = x.split(\" \")\n",
    "    \n",
    "    key_i = np.random.choice([0,1])\n",
    "    if key_i == 0:\n",
    "        for k in keywords1:\n",
    "            insensitive = re.compile(re.escape(k), re.IGNORECASE)\n",
    "            w =  np.random.randint(0,len(words)-1)\n",
    "            x = insensitive.sub(words[w], x)\n",
    "    else:\n",
    "        for k in keywords2:\n",
    "            insensitive = re.compile(re.escape(k), re.IGNORECASE)\n",
    "            w =  np.random.randint(0,len(words)-1)\n",
    "            x = insensitive.sub(words[w], x)\n",
    "    return x\n",
    "\n",
    "def randomly_add_keywords(x):\n",
    "    \n",
    "    key_i1 = np.random.randint(0,len(keywords1)-1)\n",
    "    key_i2 = np.random.randint(0,len(keywords2)-1)\n",
    "    \n",
    "    key_1 = keywords1[key_i1]\n",
    "    keys_2 = keywords2[:key_i2] + keywords2[key_i2+1:]\n",
    "        \n",
    "    words = x.split(\" \")\n",
    "    l1 =  np.random.randint(0,len(words)-1)\n",
    "    l2 =  np.random.randint(0,len(words)-1)\n",
    "    l3 =  np.random.randint(0,len(words)-1)\n",
    "    \n",
    "    words.insert(l1, key_1)\n",
    "    words.insert(l2, keys_2[0])\n",
    "    words.insert(l3, keys_2[1])\n",
    "\n",
    "    return \" \".join(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_unique = load_unique_abstract(train_data_file).pipe(self_label)\n",
    "df_test_unique = load_unique_abstract(test_data_file).pipe(self_label)\n",
    "df_val_unique = load_unique_abstract(val_data_file).pipe(self_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>self_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10047461</td>\n",
       "      <td>Cyclin E-cdk2 activation is associated with ce...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10095983</td>\n",
       "      <td>New aspects in the management of obesity: oper...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10200320</td>\n",
       "      <td>Cyclopentenone prostaglandins suppress activat...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract_id                                           abstract  self_label\n",
       "0    10047461  Cyclin E-cdk2 activation is associated with ce...       False\n",
       "1    10095983  New aspects in the management of obesity: oper...       False\n",
       "2    10200320  Cyclopentenone prostaglandins suppress activat...        True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_unique.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    628\n",
       "True     139\n",
       "Name: self_label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_unique[\"self_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    513\n",
       "True     107\n",
       "Name: self_label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_unique[\"self_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    371\n",
       "True      72\n",
       "Name: self_label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_unique[\"self_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_s3(df, s3_dest):\n",
    "    b = io.StringIO()\n",
    "    df.to_json(b)\n",
    "    \n",
    "    sagemaker.s3.S3Uploader.upload_string_as_file_body(b.getvalue(), s3_dest)\n",
    "    \n",
    "    \n",
    "def s3_json_to_df(s3_src):\n",
    "   \n",
    "    \n",
    "    json_str = sagemaker.s3.S3Downloader.read_file( s3_src)\n",
    "    b = io.StringIO(json_str) \n",
    "    df = pd.read_json(b)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample(df):\n",
    "    b = io.StringIO()\n",
    "    df.sample(n=10).to_json(\"self-supervised-sample.json\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>self_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28552592</td>\n",
       "      <td>Concurrent anticipation of two object dimensio...</td>\n",
       "      <td>The anticipation of more than one object dimen...</td>\n",
       "      <td>{'year': '2017', 'month': '08', 'day': None}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28552593</td>\n",
       "      <td>Tyrphostin A9 improves blastocyst development ...</td>\n",
       "      <td>Mitochondrial dynamics are associated with the...</td>\n",
       "      <td>{'year': '2017', 'month': '07', 'day': None}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28552595</td>\n",
       "      <td>Both non-covalent and covalent interactions we...</td>\n",
       "      <td>Persimmon tannin (PT) has been shown to inhibi...</td>\n",
       "      <td>{'year': '2017', 'month': 'Jul', 'day': None}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28552594</td>\n",
       "      <td>Plasma concentration and cardiovascular effect...</td>\n",
       "      <td>We investigated the plasma concentrations and ...</td>\n",
       "      <td>{'year': '2017', 'month': 'May', 'day': None}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28552596</td>\n",
       "      <td>Gram-scale purification of aconitine and ident...</td>\n",
       "      <td>Aconitum karacolicum from northern Kyrgyzstan ...</td>\n",
       "      <td>{'year': '2017', 'month': 'Jul', 'day': None}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   abstract_id                                      article_title  \\\n",
       "0     28552592  Concurrent anticipation of two object dimensio...   \n",
       "1     28552593  Tyrphostin A9 improves blastocyst development ...   \n",
       "2     28552595  Both non-covalent and covalent interactions we...   \n",
       "3     28552594  Plasma concentration and cardiovascular effect...   \n",
       "4     28552596  Gram-scale purification of aconitine and ident...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  The anticipation of more than one object dimen...   \n",
       "1  Mitochondrial dynamics are associated with the...   \n",
       "2  Persimmon tannin (PT) has been shown to inhibi...   \n",
       "3  We investigated the plasma concentrations and ...   \n",
       "4  Aconitum karacolicum from northern Kyrgyzstan ...   \n",
       "\n",
       "                                        pub_date  self_label  \n",
       "0   {'year': '2017', 'month': '08', 'day': None}       False  \n",
       "1   {'year': '2017', 'month': '07', 'day': None}       False  \n",
       "2  {'year': '2017', 'month': 'Jul', 'day': None}       False  \n",
       "3  {'year': '2017', 'month': 'May', 'day': None}       False  \n",
       "4  {'year': '2017', 'month': 'Jul', 'day': None}       False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pubmed_extra = pd.concat([s3_json_to_df(s).rename(columns = {\n",
    "    \"article_abstract\" : \"abstract\",\n",
    "    \"pubmed_id\" : \"abstract_id\"\n",
    "}) for s in s3_external_sources])\n",
    "df_pubmed_extra = df_pubmed_extra.pipe(self_label)\n",
    "df_pubmed_extra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    72082\n",
       "True      2578\n",
       "Name: self_label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pubmed_extra.self_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sample(df_train_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_to_s3(df_train_unique, \"s3://aegovan-data/self-supervised/train.json\" )\n",
    "upload_to_s3(df_val_unique, \"s3://aegovan-data/self-supervised/val.json\" )\n",
    "upload_to_s3(df_test_unique, \"s3://aegovan-data/self-supervised/test.json\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetize_abstract(label, abstract):\n",
    "    if label == True:\n",
    "        return randomly_substitute_keywords(abstract)\n",
    "    else:\n",
    "        return randomly_add_keywords(abstract)\n",
    "\n",
    "def create_n_synthetics(df,  synthetic_size ):\n",
    "    synth_i = 0\n",
    "    \n",
    "    result = [df]\n",
    "    \n",
    "    while  synth_i < synthetic_size:\n",
    "        sample_size = min(len(df),  synthetic_size-synth_i)\n",
    "        \n",
    "        synthetic_indices = np.random.choice(df.index, sample_size, replace=False)\n",
    "        \n",
    "   \n",
    "        df_substitute = df[ df.index.isin (synthetic_indices)].copy(deep=True)\n",
    "\n",
    "        df_substitute[\"abstract\"] = df_substitute.apply(lambda r:synthetize_abstract(r[\"self_label\"],r[\"abstract\"]),  axis=1)\n",
    "        df_substitute[\"abstract_id\"] = df_substitute[\"abstract_id\"].apply(lambda x: f\"{x}_1\")\n",
    "        df_substitute[\"is_synthetic\"] = True\n",
    "        result.append(df_substitute)\n",
    "        \n",
    "        synth_i += sample_size\n",
    "\n",
    "    \n",
    "    df_result = pd.concat(result).reset_index()\n",
    "    \n",
    "    df_result = df_result.pipe(self_label)\n",
    "    \n",
    "    \n",
    "    assert len(df_result) == len(df) + synthetic_size, f\"Length do not match {len(df_result)} =={ len(df)+synthetic_size}\"\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "\n",
    "def create_n_from_existing(df, df_source, synthetic_size ):\n",
    "    \n",
    "    result = [df]\n",
    " \n",
    "    df_extra = df_source.sample(n=synthetic_size)[[\"abstract_id\", \"abstract\"]].copy(deep=True)\n",
    "\n",
    "    df_extra[\"is_extra\"] = True\n",
    "    \n",
    "    result.append(df_extra)\n",
    "        \n",
    "    \n",
    "    df_result = pd.concat(result).reset_index()\n",
    "    \n",
    "    df_result = df_result.pipe(self_label)\n",
    "    \n",
    "    \n",
    "    assert len(df_result) == len(df) + synthetic_size, f\"Length do not match {len(df_result)} =={ len(df)+synthetic_size}\"\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "\n",
    "def create_synthetic_samples(df, duplicate_ratio = .1):\n",
    "    \n",
    "    df_orig_pos = df.query(\"self_label == True\")\n",
    "    df_orig_neg = df.query(\"self_label == False\")\n",
    "\n",
    "    synthetic_size= int(len(df_orig_neg) * duplicate_ratio)\n",
    "    df_pos = create_n_synthetics(df_orig_pos, synthetic_size)\n",
    "    \n",
    "    synthetic_size= int(len(df_orig_pos) * duplicate_ratio)\n",
    "    df_neg = create_n_synthetics(df_orig_neg,  synthetic_size)\n",
    "    df = pd.concat([df_pos, df_neg]).reset_index()\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "def create_existing_samples(df, df_source, ratio=0.1):\n",
    "    \n",
    "    df_orig_pos = df.query(\"self_label == True\")\n",
    "    df_orig_neg = df.query(\"self_label == False\")\n",
    "\n",
    "    synthetic_size= int(len(df_orig_pos) * ratio)\n",
    "    df_pos = create_n_from_existing(df_orig_pos, df_source.query(\"self_label == True\"), synthetic_size)\n",
    "    \n",
    "    synthetic_size= int(len(df_orig_neg) * ratio)\n",
    "    df_neg = create_n_from_existing(df_orig_neg, df_source.query(\"self_label == False\"), synthetic_size)\n",
    "    df = pd.concat([df_pos, df_neg]).reset_index()\n",
    "    \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_unique.query(\"self_label == True\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fake():\n",
    "    ratios = [.5, 1,2,3,4,5,6,7, 8, 9, 10 ]\n",
    "    for r in ratios:\n",
    "        df_train_fake = df_train_unique.pipe(create_synthetic_samples, r).drop_duplicates(subset=['abstract'])\n",
    "        df_test_fake = df_test_unique.pipe(create_synthetic_samples, r).drop_duplicates(subset=['abstract'])\n",
    "        df_val_fake = df_val_unique.pipe(create_synthetic_samples, r).drop_duplicates(subset=['abstract'])\n",
    "\n",
    "        true_label = df_train_fake.query(\"self_label == True\").shape[0]\n",
    "        unique = df_train_fake[\"abstract_id\"].apply(lambda x: x.split(\"_\")[0]).nunique()\n",
    "        total = df_train_fake.shape[0]\n",
    "        \n",
    "\n",
    "        suffix=f\"{total}_{unique}_{true_label}\"\n",
    "        \n",
    "        print(suffix, true_label/total)\n",
    "        \n",
    "        upload_to_s3(df_train_fake, f\"s3://aegovan-data/self-supervised-fake/{suffix}/train.json\" )\n",
    "        upload_to_s3(df_val_fake, f\"s3://aegovan-data/self-supervised-fake/{suffix}/val.json\" )\n",
    "        upload_to_s3(df_test_fake, f\"s3://aegovan-data/self-supervised-fake/{suffix}/test.json\" )\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def create_real_random():\n",
    "    ratios = [.5, 1,2,3,4,5,6,7, 8, 9, 10 ]\n",
    "    for r in ratios:\n",
    "        df_train_fake = df_train_unique.pipe(create_existing_samples, df_pubmed_extra, r).drop_duplicates(subset=['abstract'])\n",
    "        df_test_fake = df_test_unique.pipe(create_existing_samples, df_pubmed_extra, r).drop_duplicates(subset=['abstract'])\n",
    "        df_val_fake = df_val_unique.pipe(create_existing_samples, df_pubmed_extra, r).drop_duplicates(subset=['abstract'])\n",
    "\n",
    "        true_label = df_train_fake.query(\"self_label == True\").shape[0]\n",
    "        unique = df_train_fake[\"abstract_id\"].nunique()\n",
    "        total = df_train_fake.shape[0]\n",
    "        \n",
    "\n",
    "        suffix=f\"{total}_{unique}_{true_label}\"\n",
    "        \n",
    "        print(suffix, true_label/total)\n",
    "        \n",
    "        upload_to_s3(df_train_fake, f\"s3://aegovan-data/self-supervised-real/{suffix}/train.json\" )\n",
    "        upload_to_s3(df_val_fake, f\"s3://aegovan-data/self-supervised-real/{suffix}/val.json\" )\n",
    "        upload_to_s3(df_test_fake, f\"s3://aegovan-data/self-supervised-real/{suffix}/test.json\" )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150_1150_208 0.1808695652173913\n",
      "1533_1533_278 0.18134377038486627\n",
      "2301_2301_417 0.18122555410691005\n",
      "3068_3068_556 0.18122555410691005\n",
      "3832_3832_695 0.18136743215031315\n",
      "4602_4602_834 0.18122555410691005\n",
      "5368_5368_973 0.18125931445603577\n",
      "6133_6133_1112 0.18131420185879668\n",
      "6901_6901_1250 0.18113316910592667\n",
      "7665_7665_1390 0.18134377038486627\n",
      "8437_8437_1529 0.18122555410691005\n"
     ]
    }
   ],
   "source": [
    "create_real_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_fake()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "1149_767_213 0.185378590078329\n",
    "1531_767_286 0.1868060091443501\n",
    "2293_767_445 0.19406890536415178\n",
    "3048_767_573 0.18799212598425197\n",
    "3805_767_723 0.1900131406044678\n",
    "4558_767_882 0.193505923650724\n",
    "5271_767_1026 0.19464997154240182\n",
    "6021_767_1164 0.1933233682112606\n",
    "6754_767_1302 0.19277465205803967\n",
    "7482_767_1465 0.19580326116011762\n",
    "8217_767_1593 0.19386637458926614\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}